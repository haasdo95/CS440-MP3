---
title: |
  | CS 440/ECE 448 Artificial Intelligence
  | Assignment 3: Naive Bayes Classification
author: Haoen CUI^[Haoen CUI's Email hcui10@illinois.edu], Guohao (Holden) DOU^[Guohao (Holden) DOU's Email gdou2@illinois.edu], Chuchao LUO^[Chuchao LUO's Email chuchao2@illinois.edu]
date: "November 27, 2017"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    number_sections: true
    fig_width: 7
    fig_height: 6
    fig_caption: true
    df_print: kable
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

\newpage

# Part 1: Digit Classification

## Single Pixels as Features (For Everybody)

### Implementation

We treated this problem as a special case of *pixel group as features* where the pixel groups are simply disjoint and of size 1 by 1. Please see the next section for details (e.g choice of Laplace smoothing constant, classification rates, and confusion matrices).  

### Posterior Probabilities: Highest and Lowest

Test examples with largest and smallest posterior probabilities for each digit are shown below.  

```{r, echo = FALSE}
files <- list.files("img/prototypical/") 
for(file.name in files){
  path.to.file <- file.path("img/prototypical", file.name)
  file.con  <- file(path.to.file, open = "r")
  file.lines <- readLines(file.con)
  for(i in 1:length(file.lines)) {
    print(file.lines[i])
  }
  close(file.con)
}
```

### Visualization of Likelihoods and Odds Ratios

We interpreted `pairs of digits that have the highest confusion rates` as `pairs without misclassifications`. Hence, we chose pairs `(0, 9)`, `(1, 8)`, `(2, 5)`, and `(3, 4)` (randomly out of all eligible pairs). The plots are shown below. We tried several different color maps, but none of them match exactly with the example on the assignment page. The following are the closest version we can get. Though the color maps are different, they convey the same information. Also, note that the smoother used to generate these results will be described as a special case with disjoint kernel size `(1, 1)` in the next section.  

```{r, echo = FALSE, results = 'asis'}
files <- list.files("img/heatmap/")
for(file.name in files){
  path.to.file <- file.path("img/heatmap", file.name)
  pair <- substr(file.name, start = 9, stop = nchar(file.name)-4)
  caption <- paste("Heat Maps of Pair = ", pair, sep = "")
  cat(paste("![", caption, "](",path.to.file,"){height=250px}", sep = ""), sep = "\n")
}
```


## Pixel Groups as Features (For Four-Credit Students)  
### Implementation

### Choice of Smoothing Constant: 10-Fold Cross Validation

We used 10-fold cross validation to select the smoothing constant. To be specific,   

* We randomly assigned a fold number (out of 1 to 10) to each record in the training set.   
* Then, we iterate through all potential smoothers on the each fold.   
* For a given smoother and a selected fold number, the selected fold will serve as the validation set and the remaining training set will be used to train the Naive Bayes model. We can calculate a performance measure (in this case: overall misclassification rate). Thus, we will get 10 measures for each smoother.  
* We summarized the performance of each smoother using the average of its 10 measures.  
* Finally, we selected the best smoother based on the aggregated averages.  
* **IMPORTANT NOTICE**: testing set is not being used in the entire cross validation phase. It is only used once for testing purposes. Relevant results (e.g. plots and prototypicals) are generated based on these tests.  

We considered smoothers in the list `smoothers = [0.1, 0.5, 1, 2, 4, 8]`. The best smoothers selected for different kernel sizes are shown below. The entire assignment used the same cross-validation methodology. Hence, we will not repeat this section again.   
```{r, echo = FALSE}
smoother.table <- 
  rbind(c("Disjoint"   , "(1, 1)", "0.5"), 
        c("Disjoint"   , "(2, 2)", "0.1"), 
        c("Disjoint"   , "(2, 4)", "0.1"), 
        c("Disjoint"   , "(4, 2)", "0.1"), 
        c("Disjoint"   , "(4, 4)", "0.1"), 
        c("Overlapping", "(2, 2)", "0.1"), 
        c("Overlapping", "(2, 4)", "0.1"), 
        c("Overlapping", "(4, 2)", "0.1"), 
        c("Overlapping", "(4, 4)", "0.1"), 
        c("Overlapping", "(2, 3)", "0.1"), 
        c("Overlapping", "(3, 2)", "0.1"), 
        c("Overlapping", "(3, 3)", "0.1"))
colnames(smoother.table) <- c("Kernel Type", "Kernel Size", "Best Smoother Value")
rownames(smoother.table) <- c()
knitr::kable(smoother.table, caption = "Choice of Smoothing Constant Using 10-Fold Cross Validation")
```


### Accuracy on Test Set: Classification Rate and Confusion Matrix  


```{r, echo = FALSE, results = 'asis'}
files <- list.files("img/conf_mat/")
for(file.name in files){
  path.to.file <- file.path("img/conf_mat", file.name)
  plot.type <- substr(file.name, start = 10, stop = 13)
  kernel.size <- substr(file.name, start = 14, stop = nchar(file.name)-4)
  caption <- paste(ifelse(plot.type == "disj", 
                          "Confusion Matrix with Disjoint Kernel Size = ", 
                          "Confusion Matrix with Overlapping Kernel Size = "), 
                   kernel.size, sep = "")
  cat(paste("![", caption, "](",path.to.file,"){height=250px}", sep = ""), sep = "\n")
}
```


```{r, echo = FALSE}
accuracy.table <- 
  rbind(c("Disjoint"   , "(1, 1)", "77.0 %"), 
        c("Disjoint"   , "(2, 2)", "85.8 %"), 
        c("Disjoint"   , "(2, 4)", "88.6 %"), 
        c("Disjoint"   , "(4, 2)", "87.9 %"), 
        c("Disjoint"   , "(4, 4)", "84.6 %"), 
        c("Overlapping", "(2, 2)", "87.1 %"), 
        c("Overlapping", "(2, 4)", "89.6 %"), 
        c("Overlapping", "(4, 2)", "90.2 %"), 
        c("Overlapping", "(4, 4)", "87.4 %"), 
        c("Overlapping", "(2, 3)", "88.8 %"), 
        c("Overlapping", "(3, 2)", "90.0 %"), 
        c("Overlapping", "(3, 3)", "90.0 %"))
colnames(accuracy.table) <- c("Kernel Type", "Kernel Size", "Overall Accuracy")
rownames(accuracy.table) <- c()
knitr::kable(accuracy.table, caption = "Overall Accuracy on Different Kernels with Best Smoothers")
```

### Trends for Different Feature Sets
The following are some general trends we found,   

* with same kernel size, overlapping kernels tend to perform better than disjoint kernels because overlapping ones contain more features.  
* with the same kernel type, increase in kernel size does not necessary translate to better performance because at some point using additional features may be merely overfitting.  
* by trying out different kernels and tuning the smoother, one can achieve a much higher performance than merely using the default 1 by 1 pixels.  


### Running Time for Different Feature Sets

#### Training

#### Testing

## Extra Credit

### Ternary Features

This part is relatively easy. We merely changed the way we read in files to incorporate ternary features. Then, we run the same process as the one we used for binary features with disjoint 1 by 1 kernel. Finally, we ended up with the same best smoother (`= 0.5`) and the resulting overall classification rate is 77.1 %. There is not much improvements.    

![Ternary Confusion Matrix](img/ternary.png)

### Naive Bayes Classifier on Face Data



---

# Part 2: Audio Classification

## Binary Classification: Hebrew Words of "Yes" and "No" (For Everybody)

### Implementation

### Classification Rate and Confusion Matrix

We used the same logic of 10-fold cross validation to select the best smoother. The potential list we considered is `smoothers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`. The best smoother we selected is `best_smoother = 2` and its average classificaiton rate on the 10 folds is 98.15%. With this smoother, the confusion matrix is shown below.  

![Confusion Matrix for Hebrew Words (Y/N)](img/Hebrew_Words_Conf_Mat.png)

## Multi-Class Classification: Audio Digits 1-5 Spoken by Four Different Speakers (For Four-Credit Students)

### Implementation

### Accuracy: Classification Rate and Confusion Matrix

Again, smoother is chosed based on cross validation described above. The final overall accuracy with the best smoother is 85 % and the confusion matrix is shown below. 

![Confusion Matrix for Audio Digits](img/Audio_Digits_Conf_Mat.png)

## Extra Credit

### Binary Classification on Unsegmented Data

Using the `splitData.run()` function we designed, we run the binary Naive Bayes classifier on the splitted data again. Meanwhile, smoother is selected using cross validation as described above. The overall accuracy is 96 % and the confusion matrix is shown below.  

![Confusion Matrix for Hebrew Words (Y/N) with Unsegmented Data](img/Hebrew_Words_Unsegmented_Conf_Mat.png)

### Alternative Method (RNN) on Hebrew Yes-No Corpus


![Confusion Matrix for Hebrew Words (Y/N) Using RNN](img/Hebrew_Words_RNN_Conf_Mat.png)

### Average-Column Method on Hebrew Yes-No Corpus

We implemented the method as described in the assignment along with smoother selection using cross validation explained above. The confusion matrix is shown below. As noted in the assignment, our result was not as good as the basline but the computational complexity (e.g. time taken) was lower.  

![Confusion Matrix for Hebrew Words (Y/N) Using Average Column Method](img/Hebrew_Words_Avg_Col_Conf_Mat.png)

---

# Appendix {-}

In this appendix section, we explain what is contained in the submission package so that one can refer to the raw files in case that the report above was not clear on any points (which should not be the case). Note that "`.`" in the following table stands for the path to the submission folder, i.e. "`PATH/TO/CS440MP3`".   


```{r, echo = FALSE}
appendix <- 
  rbind(c("`./part1/log`"                 , "Execuion logs"), 
        c("`./part2/log`"                 , "Execuion logs"), 
        c("`./*/*.pkl`"                   , "Training results"), 
        c("`./part1/cv_fc.py`"            , " "), 
        c("`./part1/deserializer.py`"     , " "), 
        c("`./part1/deserializer_face.py`", " "), 
        c("`./part1/fc_utils.py`"         , " "), 
        c("`./part1/odds.py`"             , " "), 
        c("`./part1/ternary2binary.py`"   , " "), 
        c("`./part1/test.py`"             , " "), 
        c("`./part1/test_ec.py`"          , " "), 
        c("`./part1/test_fc.py`"          , " "), 
        c("`./part1/train.py`"            , " "), 
        c("`./part1/train_ec.py`"         , " "), 
        c("`./part1/train_fc.py`"         , " "), 
        c("`./part1/disj_rec.txt`"        , " "), 
        c("`./part1/ovlp_rec.txt`"        , " "), 
        c("`./part2/YESNO.py`"            , " "), 
        c("`./part2/YESNO_avg_col.py`"    , " "), 
        c("`./part2/cv.py`"               , " "), 
        c("`./part2/dataLoader.py`"       , " "), 
        c("`./part2/ec2.py`"              , " "), 
        c("`./part2/numberClassifier.py`" , " "), 
        c("`./part2/rnn.py`"              , " "), 
        c("`./part2/splitData.py`"        , " "), 
        c("`./part2/tensorize.py`"        , " "), 
        c("`./part2/test.py`"             , " "), 
        c("`./part2/train.py`"            , " "), 
        c("`./part2/utils.py`"            , " "), 
        c("`./visualization/viz.py`"      , "Python code for visualizations"), 
        c("`./report`"                    , "Reports and supporting documents to generate the report"))
colnames(appendix) <- c("File", "Usage or Comments")
rownames(appendix) <- c()
knitr::kable(appendix, caption = "Annotations of Files Submitted")
```


# Statement of Individual Contribution {-}

```{r, echo = FALSE}
contribution.table <- 
  rbind(c("hcui10", "visualization, report, and ideas generation"), 
        c("gdou2", "part 1 (algorithm design and programming) and ideas generation"), 
        c("chuchao2", "part 2 (algorithm design and programming) and ideas generation"))
colnames(contribution.table) <- c("NetID", "Contribution")
rownames(contribution.table) <- c("Haoen CUI", "Guohao DOU", "Chuchao LUO")
knitr::kable(contribution.table, caption = "Statement of Individual Contribution")
```
